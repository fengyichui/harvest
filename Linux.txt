
*Linux* *Bash* 

1. *iconv* 编码转换: 
    $ iconv -f UNICODELITTLE -t MS-ANSI -c resource.h > re.h      ~
    |-f| : 输入编码
    |-t| : 输出编码
    |-c| : 忽略不可转换的字符

2. *xargs* 从标准输入中构造可执行的命令行： 
    build and execute command lines from standard input
    一般形式:
    xargs [-I replace-str] [-n max-args] [command] [initial-arguments]   ~

    |-I| |replace-str|  使用 replace-str 代替输入的参数
    |-n| |max-args|     每次提供的最大参数个数
    |-d| |sep-char|     每个参数的分隔符，当文件内包含空格的时候非常有用，如：`find -name "*.txt" | xargs -d '\n' chmod -x`

    xargs会把标准输入的数据的所有回车去掉.
    当xargs什么参数都不加的时候, 默认把标准输入的参数作为执行命令最尾的参数.

    对xargs内执行多个命令:
         使用sh -c "commands"方式传入多个指令，如：
         $ ls | xargs -n1 -I{} sh -c 'echo -e {} && cat {}' ~

    eg: 
        $ find -type f | xargs -I{} mv {} ./path/       #查找当前目录及子目录的文件,并把这些文件移动到./path/下   ~
        $ find -name '*.[ch]' | xargs grep -E 'define'  #在当前目录下查找c和h文件中出现的'define'的位置           ~
        $ findfile.sh 'uvproj' | xargs -I{} -n1 perl test.pl -f={}  #对findfile输出的结果, 循环调用perl test.pl -f='file' 脚本 ~

3. Bash 常用快捷操作                         *Bash快捷操作*
    |Ctrl+a|   切换到命令行开始
    |Ctrl+e|   切换到命令行末尾
    |Ctrl+l|   清除屏幕内容，效果等同于clear
    |Ctrl+u|   清除剪切光标之前的内容, 并复制到bash自己的剪切板
    |Ctrl+k|   剪切清除光标之后的内容, 并复制到bash自己的剪切板
    |Ctrl+y|   粘贴刚才所删除的字符
    |Ctrl+r|   在历史命令中查找
    |Ctrl+c|   终止命令
    |Ctrl+d|   退出shell，logout
    |Ctrl+z|   转 入后台运行但是当前用户推出将终止。可以在命令前加 nohup 或者在命令后加&
    |history|  显示你所有执行过的编号+历史命令。
    |!125|     执行历史记录中编号为125的命令
    |!!|       重复执行最后一条命令 执行命令后忘记加速度 弥补方法sudo !!
    |!$|       使用上一条命令的最后一个参数;
    |!:n|      使用上一条命令的第n个参数;
    鼠标中键 将当前选中的文本复制到命令行;
    |Shift-insert| 从系统剪切板粘贴

4. 更改linux的命令搜索路径 （设置环境变量）    *linux命令搜索路径*     
    位置：/etc/profile 文件
          PATH的内容就是命令的搜索路径。
    使用Cygwin的时候该命令可能很有用额。。。    

5. 需要执行三个程序，它们是独立的，不需要等待其他命令执行结束。
    解决方案：
    在命令后放一个'&',使得该命令在后台运行。这样你可以用如下的方法同时执行这三个程序。
    $ long &
    $ vim a.cpp &
    $ other &

6. 磁盘使用检测             *Bash磁盘检测*  *du*   *df*
    $ du -a 当前文件夹下所有文件和文件夹使用情况汇总 (disk usage) 
    $ df 磁盘信息
    |du| 详解:
        |--max-depth=N| ：最大目录深度，=1时显示当前目录下所有文件夹大小，=0时显示当前目录大小(等于-s)
        |-s|            : 统计du的参数中目录或文件的容量大小
        |-h|            ：以可读性较好的方式显示大小，MB, GB, KB...
        |-b|, |-k|, |-m|    : 以byte，KB，MB格式显示大小
        |-a|            ：不仅仅显示文件夹的大小, 同时显示所有文件大小

    例子：
        统计当前文件夹下一级子目录和一级文件的容量
        $ du -a --max-depth=1         ~

        遍历目录：
        $ du -a | awk -v IGNORECASE=1 'sub(/^[.0-9A-Z]+\s+/, ""){}; gsub(/ /, "\\ "){}; /\.(h|c)$/' | xargs perl -i $0  ~
        $ find -type f -iregex ""          ~

7. *grep* 使用：
    选项：
    |-R|     ：遍历目录。 同 --recursive
    |-i|     ：忽略大小写
    |-E|     ：使用ERE, 默认使用BRE
    |-n|     ：打印行
    |--color|：高亮显示。可以在.bashrc中加入 alias grep='grep --color -n' 

    eg: 
        $ grep -iR 'find me' *       #在当前目录和子目录下查找find me, 忽略大小写;     ~
        $ grep -E '^[A-Z]?.*$' *.c   #在当前目录下的C文件中查找正则表达式''       ~

8. 当命令行的文件参数为 '-' 时表示从标准输入获取数据      *Bash标准输入*
    eg: grep -iR 'the girl' * | gvim -        #使用gvim编辑grep获得的数据         ~
    Note 注意以下两种用法的区别:
        a. $ history           | grep 'find_data' -       # 对history输出的内容进行搜索~
        b. $ findfile.sh 'c|h' | xargs grep 'find_data'   # 对findfile.sh输出的每个文件里的内容进行搜索~

9. *sort* 使用
    默认:
    不忽略行头的空白, ASCII码升序, 域分割符空格, 行开始
    
    选项:
    |-n| {--numric-sort} 根据数字的大小排序
    |-r| {--reverse} 降序排序, 默认是升序
    |-b| {--ignore-leading-blanks} 忽略行头的空白
    |-f| {--ignore-case} 忽略大小写

    |-c| {--check} 检查文件是否已经排好序
    |-M| {--month-sort} 按月份排序 eg: (unknown) < 'JAN' < ... < 'DEC'
    |-h| {--human-numeric-sort} 用可读的数字比较 eg: 2k, 1G
    |-u| {--unique} 去掉重复行

    |-k| {--key} 通过key指定的域进行排序
    |-t| {--field-separator} 指定域分割符; 默认是: 空格
    
    关于 |-k| |-t| 选项的说明(精简):
        1>. syntax : -t |Separator| -k |FieldStart||*.CharStart* Modifier
            eg     : -t   ';'     -k     1     .    2     fr
            explain: 使用;作为域分隔符, 从第1个域的第2个字符开始进行忽略大小写的降序排序
        2>. 关于'域': 
            a. 默认域分割符是空格;
            b. 如文件中某行数据为 'abc 123 efg' 则: 'abc'是第1个域; '123'是第2个域 'efg'是第3个域

    eg: 
        $sort -t ';' -k 1.2fr file.txt   #使用;作为域分隔符, 从第1个域的第2个字符开始进行忽略大小写的降序排序   ~
        $sort -nb file.txt               #忽略行头的空白, 以行开始的数字大小对文件进行排序      ~

10. 常用文件操作命令
    a. 创建文件夹 *mkdir*
        mkdir DIR...
    b. 创建文件 *touch* 
        touch FILE...
        gvim FILE...
        >FILE...
    c.删除文件或文件夹 *rm* 
        rm  FILE...
        rm -r DIR...
        |-i| 删除文件前需要用户(y/n)确认
    d.拷贝文件或文件夹 *cp*
        cp SOURCE_FILE DEST_FILE
        cp SOURCE_FILE... DEST_DIR
        cp -r SOURCE_DIR... DEST_DIR  #如果DEST_DIR不存在则创建
    e.移动文件或文件夹 *mv*
        mv SOURCE_FILE DEST_FILE
        mv SOURCE_FILE... DEST_DIR
        mv SOURCE_DIR... DEST_DIR 
    f.查看文件 *cat* *less* *more*
        cat FILE...
        less FILE...
        more FILE...

11. Shell 科学计算器
    语法: printf "%d" $((...)) 或 echo $((...))
          其中, $(( )) 是用来作整数运算的, "..."为计算表达式, "%d"为结果展示方式

    算术运算符:
        - +        单目负号和正号
        ! ~        逻辑取反，按位取反
        **         指数
        * / %      乘，除，求余
        + -        加，减
        << >>      按位左移，按位右移
        <= >= < >  比较
        == !=      相等，不等
        &          按位与
        ^          按位异或
        |          按位或
        &&         逻辑与
        ||         逻辑或

    进制转换: 
        输入进制: ([base#]n)
            0xXX : 16进制 同16#XX
            XX   : 10进制 同10#XX
            0XX  : 8 进制 同8#XX
            2#XX : 2 进制
            24#XX: 24进制
        输出进制: printf的 %d %x

    中间值记忆:
        记录: n=$((...))   # "="左右不能有空格
        使用: $(($n * 10))

12. *xxd* 十六进制dump工具 使用

    |-b|  二进制显示, 默认十六进制

    |-c| {n}  每行显示多少字节, 默认16. 例如: -c32 (每行显示32字节)
    |-g| {n}  每组包含多少字节, 默认2. 例如: -g4 (每组包含4字节)

    |-s| {[+][-]seek}  dump的开始位置, 默认是开头. +:从开头算 -:从末尾算
    |-l| {len}         从开始位置dump的长度, 默认是所有.

    |-u|  输出[a-z]大写, 默认小写

    |-ps| 以 "intel hex file format" 显示
    |-i|  以C语言{include}数组格式显示

    |-r|  还原

    例子:
        1 以4个byte为一组, 并且把每组数据的字节序翻转, 12345678 => 78563412
           $ xxd -g4 "file.bin" | sed 's/ \([0-9a-f]\{2\}\)\([0-9a-f]\{2\}\)\([0-9a-f]\{2\}\)\([0-9a-f]\{2\}\)/ \4\3\2\1/g'   ~

        2 Create a 65537 byte file with all bytes 0x00, except for the last one which is 'A' (hex 0x41).
           $ echo "010000: 41" | xxd -r > file  ~

        3 Print 3 lines (hex 0x30 bytes) from the end of file.
           $ xxd -s -0x30 file ~

        4 Hexdump the first 120 bytes, with 12 octets per line, 4 octets per group.
           $ xxd -l120 -c12 -g4 file.bin  ~
            >
             0000000: e8440010 c1000010 cf000010  .D..........
             000000c: d1000010 d3000010 d5000010  ............
             0000018: d7000010 00000000 00000000  ............
             0000024: 00000000 00000000 d9000010  ............
             0000030: db000010 00000000 dd000010  ............
             000003c: df000010 11050010 e1000010  ............
             0000048: e1000010 25040010 e1000010  ....%.......
             0000054: 45050010 e1000010 e1000010  E...........
             0000060: e1000010 00000000 55070010  ........U...
             000006c: f1060010 e1000010 e1000010  ............
<

13. ln 创建链接
    ln [option] source_file dist_file 
    |-f| 建立时，将同档案名删除.
    |-s| 建立的软连接

    eg:
        1、ln -s abc cde 建立abc的软连接->cde
        2、ln abc cde    建立abc的硬连接->cde

    软链接与硬链接的区别:
    硬链接可认为是一个文件拥有两个文件名, 当前目录为硬链接文件所在的目录
    而软链接则是系统新建一个链接文件, 此文件指向其所要指的文件, 当前目录为所指文件的目录。

14. 补丁 diff和patch
    制作补丁文件: >
    diff -urN dir_a/ dir_b/ >c.patch   # dir_a是原始文件夹，dir_b是修改后的文件夹，C称为dir_a的补丁文件。
<    打补丁: >
    patch -p1 dir_a/ <c.patch           # 应用c.patch到dir_a，使dir_a成为dir_b

15. 压缩
    .tar 
    解包：tar xvf FileName.tar
    打包：tar cvf FileName.tar DirName
    （注：tar是打包，不是压缩！）
    ———————————————
    .gz
    解压1：gunzip FileName.gz
    解压2：gzip -d FileName.gz
    压缩：gzip FileName

    .tar.gz 和 .tgz
    解压：tar zxvf FileName.tar.gz
    压缩：tar zcvf FileName.tar.gz DirName
    ———————————————
    .bz2
    解压1：bzip2 -d FileName.bz2
    解压2：bunzip2 FileName.bz2
    压缩： bzip2 -z FileName

    .tar.bz2
    解压：tar jxvf FileName.tar.bz2
    压缩：tar jcvf FileName.tar.bz2 DirName
    ———————————————
    .bz
    解压1：bzip2 -d FileName.bz
    解压2：bunzip2 FileName.bz
    压缩：未知

    .tar.bz
    解压：tar jxvf FileName.tar.bz
    压缩：未知
    ———————————————
    .Z
    解压：uncompress FileName.Z
    压缩：compress FileName
    .tar.Z

    解压：tar Zxvf FileName.tar.Z
    压缩：tar Zcvf FileName.tar.Z DirName
    ———————————————
    .zip
    解压：unzip FileName.zip
    压缩：zip FileName.zip DirName
    ———————————————
    .rar
    解压：rar x FileName.rar
    压缩：rar a FileName.rar DirName
    ———————————————
    .lha
    解压：lha -e FileName.lha
    压缩：lha -a FileName.lha FileName
    ———————————————
    .rpm
    解包：rpm2cpio FileName.rpm | cpio -div
    ———————————————
    .deb
    解包：ar p FileName.deb data.tar.gz | tar zxf -
    ———————————————
    .tar .tgz .tar.gz .tar.Z .tar.bz .tar.bz2 .zip .cpio .rpm .deb .slp .arj .rar .ace .lha .lzh .lzx .lzs .arc .sda .sfx .lnx .zoo .cab .kar .cpt .pit .sit .sea
    解压：sEx x FileName.*
    压缩：sEx a FileName.* FileName

16. AWK

    awk处理的单位为行(record), 即对每一行调用处理操作. 

    基本命令格式为：
        Patterns and Actions
        AWK是一种基于行的语言。
        语言格式是：
            patterns{actions} 即：先patterns后大括号action; ~
            解释：模式成功则执行{}内的actions;
        1、有patterns, 无actions，则默认action为 ：{print}
        2、无patterns, 有actions，则默认patterns一定匹配该行
        actions 可以包括各种函数和逻辑控制语言。
        Patterns包括的内容在下面

        Patterns包括：
            BEGIN                          :所有操作的开始
            END                            :所有操作的结束
            BEGINFILE                      :当前文件的开始
            ENDFILE                        :当前文件的结束
            /regular expression/           :正在表达式
            relational expression          :关系运算
            pattern && pattern || pattern  :逻辑运算符
            pattern ? pattern : pattern    ：
            (pattern)                      ：
            ! pattern                      ：
            pattern1, pattern2             ：

        逻辑控制：
            if (condition) statement [ else statement ]
            while (condition) statement
            do statement while (condition)
            for (expr1; expr2; expr3) statement
            for (var in array) statement
            break
            continue
            delete array[index]
            delete array
            exit [ expression ]
            { statements }
            switch (expression) {
            case value|regex : statement
            ...
            [ default: statement ]
            }

    常用内嵌函数：*sub* *gsub*
        大部分C库函数可以使用

        替换第一个：sub(/regexp/, replacement [, target])
        全局替换  ：gsub(/regexp/, replacement [, target])
        长度      ：length([string])
        变小写    ：tolower(string)
        变大写    ：toupper(string)

    内建变量
        $0       当前记录（这个变量中存放着整个行的内容）
        $1~$n    当前记录的第n个字段，字段间由FS分隔

        FS       输入字段分隔符 默认是空格 field separator
        RS       输入的记录分隔符， 默认为换行符\n record separator

        OFS      输出字段分隔符， 默认也是空格 
        ORS      输出的记录分隔符，默认为换行符

        NF       当前记录中的字段个数，就是有多少列。number of fields
        NR       已经读出的记录数，就是行号，从1开始，如果有多个文件话，这个值也是不断累加中。 number of records
        FNR      当前记录数，与NR不同的是，这个值会是各个文件自己的行号

        FILENAME 当前输入文件的名字

        IGNORECASE=1 忽略大小写

    常用选项：
        -v ：-var 设置变量值，就像在BEGIN{}中定义的一样 eg: $ awk -v FS='-' 'print $1' a.txt
        -f ：使用awk脚本文件。eg: $ awk -f script.awk a.txt

    在shell中单引号和双引号的区别。(都表示字符串)
        双引号: 内部的 \what、 $x、`what 会被shell解析成为其他的值。
        单引号: 内部的值不会被shell解析。
        所以在使用awk时候一定要使用单引号

    使用例子：
        格式化输出 >
        $ awk '{print $1, $4}' netstat.txt
        $ awk '{printf "%-8s %-8s %-8s %-18s %-22s %-15s\n",$1,$2,$3,$4,$5,$6}' netstat.txt
<
        使用比较运算符 >
        $ awk '$6=="LISTEN" || $3>0 || NR==1' netstat.txt
<
        使用正则表达式 >
        $ awk '/LISTEN/' netstat.txt
        $ awk '!/LISTEN/' netstat.txt
        $ awk '$6 ~ /TIME/ || NR==1 {print NR}' netstat.txt
        $ awk '$6 !~ /WAIT/ || NR==1 {print NR}' netstat.txt
<
        使用BEGIN 和 END >
        $ awk 'BEGIN{FS=":"} {print $1, $2}' OFS="-" a.txt
        $ awk '{sum+=$5} END {print sum}' netstat.txt
<
        for的使用 >
        $ awk '{for(i=1;i<=NF;i++)printf("%dx%d=%d%s", i, NR, i*NR, i==NR?"\n":"\t")}' a.txt
        $ awk 'NR!=1{a[$6]++;} END {for (i in a) print i ", " a[i];}' netstat.txt
<
        替换(sub & gsub)： >
        $ du -a | awk -v IGNORECASE=1 'sub(/^[.0-9A-Z]+\s+/, ""){}; gsub(/ /, "\\ "){}; /\.((h)|(c))/' | xargs perl -i $0
<
        使用脚本文件 >
        $ awk -f cal.awk score.txt
        $ cat cal.awk
            #运行前
            BEGIN {
                math = 0
                english = 0
                computer = 0
                printf "NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\n"
                printf "---------------------------------------------\n"
            }
            #运行中
            {
                math+=$3
                english+=$4
                computer+=$5
                printf "%-6s %-6s %4d %8d %8d %8d\n", $1, $2, $3,$4,$5, $3+$4+$5
            }
            #运行后
            END {
                printf "---------------------------------------------\n"
                printf "  TOTAL:%10d %8d %8d \n", math, english, computer
                printf "AVERAGE:%10.2f %8.2f %8.2f\n", math/NR, english/NR, computer/NR
            }
<
    字符串连接
        直接写在一起即可: str = "0x"value; #value是一个变量

    进制转换
        10进制 -> 16进制: nHex = sprintf("0x%X", nDec);
        16进制 -> 10进制: nDec = strtonum("0x"nHex);

    位操作
        与      : and(v1,v2)
        或      : or (v1,v2)
        异或    : xor(v1,v2)
        左移    : lshift(val,count)
        右移    : rshift(val,count)
        按位取反: compl(val)

17. SED (Stream EDitor)
    SED是一种基于行的语言。

    基本格式为：
        语言格式是：
            patterns{cmd} ~
            解释：模式成功则执行{}内的cmd;
            无patterns, 有cmd，则对所有行进行处理
            默认情况，sed会把操作的结果打印到标准输出

        patterns：
            /regex/             :正在表达式
            pattern1, pattern2  :从pattern1到pattern2
            pattern, +5         :从pattern1到+5行
            pattern!            :没有匹配到pattern
            10                  :第10行

        cmd：
            s/m/a/g             :替换：把m替换成a
            a                   :append，匹配行后添加行
            i                   :insert，匹配行前插入行
            c                   :change，替换掉匹配的行
            d                   :delete，删除匹配行
            p                   :print， 匹配行 (该行可能会导致打印两边，因为默认会打印该行的)
            N                   :next，  把下一行附加到当前行进行处理
            n                   :next，  处理下一行
            q                   :quit，  退出

        控制：
            cmd1; cmd2          :将多条命令串联起来
            {cmds}              :命令打包

        常用命令行选项：
            -i                  :直接对文件进行操作，(默认将sed的结果打印到标准输出)
            -n                  :不自动打印sed的结果，只打印使用p命令的结果

    例子： >
        $ sed "s/my/your/g" pets.txt                 # s     替换所有的my为your
        $ sed -i "s/my/Hao/g" pets.txt               # s -i  直接修改文件内容
        $ sed 's/^/#/g' pets.txt                     # s     在行首加入#
        $ sed 's/<[^>]*>//g' html.txt                # s     删除html标记
        $ sed "3s/my/your/g" pets.txt                # s     仅把第3行的my替换成your
        $ sed "3,6s/my/your/g" pets.txt              # s     把第3行到第6行的my替换成your
        $ sed 's/s/S/1' my.txt                       # s     仅替换第1个s为S
        $ sed 's/s/S/3g' my.txt                      # s     替换第3个和之后的s为S
        $ sed 's/my/your/g; s/This/That/g' my.txt    # s     先替换my为your，再替换所有的This为That
        $ sed 's/my/[&]/g' my.txt                    # s &   替换所有的my为[my], &表示匹配到的内容
        $ sed '/dog/,+3s/^/# /g' pets.txt            # s +3  对匹配上dog的行和之后的3行执行替换
        $ sed 'N;N;s/my/your/' pets.txt              # N     将下一行和下下行纳入当前行执行s/my/your/
        $ sed '/my/{n;d}' pets.txt                   # n     删除匹配上my的下一行
        $ sed "1 i This is" my.txt                   # i     在第一行前插入This is
        $ sed "$ a This is" my.txt                   # a     在最一行后插入This is
        $ sed "/fish/a This is" my.txt               # a     匹配到fish的行后插入This is
        $ sed "2 c This is" my.txt                   # c     第二行替换成This is
        $ sed "/fish/c This is" my.txt               # c     匹配到fish的行替换成This is
        $ sed '/fish/d' my.txt                       # d     删除匹配带fish的行
        $ sed '2d' my.txt                            # d     删除第2行
        $ sed '2,$d' my.txt                          # d     删除第2行到最后一行
        $ sed '/fish/p' my.txt                       # p     重复打印匹配到fish的行
        $ sed -n '/fish/p' my.txt                    # p -n  仅打印match的行
        $ sed -n 's/fish/dog/p' my.txt               # p -n  仅打印match的行
        $ sed -n '/dog/,/fish/p' my.txt              # p -n  仅打印匹配上dog的行一直到匹配上fish行
        $ sed -n '1,/fish/p' my.txt                  # p -n  仅打印第一行到匹配上fish的上
        $ sed '3,6 {/This/d}' pets.txt               # {}    对第3行到第6行执行：删除匹配到This的行
        $ sed '3,6 {/This/{/fish/d}}' pets.txt       # {}    对第3行到第6行且对匹配上This的行执行：删除匹配到fish的行
        $ sed '1,${/This/d;s/That/This/g}' pets.txt  # {}    对第1行到最后一行执行：删除所有匹配到This的行，然后替换所有That为This

18. 几种POSIX流派的regex说明 >
    +---------------------------------------------------------------------------+
    | 流派      说明                                        工具                |
    | BRE       (、)、{、}必须转义，不支持+、?、|           grep、sed、vi、more | #vi有些不一样
    | GNU BRE   (、)、{、}、+、?、|必须转义                 GNU grep、GNU sed   |
    | ERE       (、)、{、}、+、?、|直接使用, \1、\2不确定   egrep、awk          |
    | GNU ERE   (、)、{、}、+、?、|直接使用, 支持\1、\2     grep –E、GNU awk    |
    +---------------------------------------------------------------------------+
    | BRE ERE 共同支持的元字符有: \.*^$[]                                       |
    +---------------------------------------------------------------------------+
<
    常用Linux/Unix工具中regex的表示法 >
    +---------------------------------------------------------------+
    | Perl        awk       grep -E   grep       sed        vi/vim  |
    | \.*^$[]     ...       ...       ...        ...        ...     |
    | +           +         +         \+         \+         \+      |
    | ?           ?         ?         \?         \?         \=      |
    | {m,n}       {m,n}     {m,n}     \{m,n\}    \{m,n\}    \{m,n}  |
    | \b          \< \>     \< \>     \< \>      \< \>      \< \>   |
    | |           |         |         \|         \|         \|      |
    | (…)         (…)       (…)       \(…\)      \(…)       \(…\)   |
    | \1 \2       不支持    \1 \2     \1 \2      \1 \2      \1 \2   |
    | (?=atom)                                              atom\@= |
    | (?!atom)                                              atom\@! |
    +---------------------------------------------------------------+

19. linux用户、组、权限

    用户组： ~
    u (user)：   拥有者
    g (group)：  拥有者所在的组
    o (others)： 其他组
    a (all)：    所有用户

    一般权限： ~
    r (Read)：    文件：具有读取文件内容的权限
                  目录：具有浏览目录的权
    w (Write)：   文件：具有新增、修改文件内容的权限
                  目录：具有删除、移动目录内文件的权限
    x (eXecute)： 文件：具有执行文件的权限
                  目录：该用户具有进入目录的权限

    特殊权限：(出现在相应域的可执行位上) ~
    s (SUID,Set UID)：   仅作用于"拥有者域"
                         文件：常作用于可执行文件。任意执行该文件的"使用者"都将获得"拥有者"的特权，如"/bin/passwd"命令就是如此
                         目录：
    s (SGID,Set GID)：   仅作用于"拥有者所在组域"
                         文件：常作用于可执行文件。任意执行该文件的"使用者"都将获得"拥有者所在的组"的特权
                         目录："使用者"在该目录创建的所有文件都获得"拥有者所在组"的特权
    t (SBIT,Sticky Bit)：仅作用于"其他组域"
                         文件：不可以作用于文件
                         目录："使用者"在该目录创建的文件只有该用户自己和ROOT可以修改，其他用户无权修改，如"/tmp"目录

    用户和组的文件路径： ~
    用户：      $UID, /etc/passwd
    组：        $GID, /etc/group
    用户口令：  /etc/shadow
    组口令：    /etc/gshadow

    用户管理命令: ~
    useradd:    添加用户
    userdel:    删除用户
    usermod:    修改用户帐号属性
    id:         查看用户的帐号属性信息
    finger:     查看用户帐号信息
    chsh:       修改用户的默认shell
    chfn:       修改注释信息
    passwd:     密码管理
    pwck:       检查用户帐号完整性

    组管理命令: ~
    groupadd:   创建组
    groupdel:   删除组
    groupmod:   修改组属性
    gpasswd：   为组设定密码
    newgrp：
    chage：     更改密码使用时间

    权限管理: ~
    chown:      改变文件的拥有者(只有管理员可以使用此命令)
    chgrp:      改变文件的拥有者的组
    chmod:      修改文件的权限
    umask:      设置默认权限的掩码。

    chmod命令: ~
        chmod [OPTION]... MODE[,MODE]... FILE...
        chmod [OPTION]... OCTAL-MODE FILE...
        MODE:
            可读式表示:
                格式为: who opcode permission
                who:
                    u 用户
                    g 组
                    o 其它
                    a 所有用户(默认)
                opcode:
                    + 增加权限
                    - 删除权限
                    = 重新分配权限 
                permission:
                    r 读
                    w 写
                    x 执行
                    s SUID SGID
                    t SBIT
            八进制表示:
                三个数字： User Group Other
                四个数字： Spacial User Group Other >
                ------------------------------
                Spacial - User - Group - Other
                SBIT:1    x:1    x:1     x:1
                SGID:2    w:2    w:2     w:2
                SUID:4    r:4    r:4     r:4
<        例子: >
        $ chmod u+x file             # 给file的属主增加执行权限
        $ chmod 751 file             # 给file的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限
        $ chmod u=rwx,g=rx,o=x file  # 上例的另一种形式
        $ chmod =r file              # 为所有用户分配读权限
        $ chmod 444 file             # 同上例
        $ chmod a-wx,a+r   file   　 # 同上例
        $ chmod -R u+r directory     # 递归地给directory目录下所有文件和子目录的属主分配读的权限
        $ chmod 4755                 # 设置GUID，给属主分配读、写和执行权限，给组和其他用户分配读、执行的权限。
<
    umask命令： ~
        umask设置了用户创建文件的默认权限，它与chmod的效果刚好相反，umask设置的是权限“补码”，而chmod设置的是文件权限码。
        一般在/etc/profile、$ [HOME]/.bash_profile或$[HOME]/.profile中设置umask值。
        默认情况下的umask值是022(可以用umask命令查看）， 此时你建立的文件默认权限是644(666-022)，建立的目录的默认权限是755(777-022)
        例子： >
        $ umask         # 读取当前文件夹的umask值
        $ umask 077     # 默认当前文件夹创建文件的权限是600，创建目录的权限是700
<
    ls -l 解析： ~
    内容如下： >
    -rwxrw-r‐-1 root root 1213 Feb 2 09:39 abc
<    - 第一个字符代表文件(-)、目录(d)，链接(l)
    - 其余字符每三个一组(rwx)，读(r)、写(w)、执行(x)、特殊(s,s,t)
        第一组rwx：文件所有者的权限是读、写和执行
        第二组rw-：与文件所有者同一组的用户的权限是读、写但不能执行
        第三组r--：不与文件所有者同组的其他用户的权限是读不能写和执行
    - 1 表示连接的文件数
    - root 表示用户
    - root 表示用户所在的组
    - 1213 表示文件大小
    - Feb 2 09:39 表示最后修改日期
    - abc 表示文件名

20. 远程登录与拷贝
    远程登录：
    - telnet
    - ssh
    远程拷贝：
    - scp: 使用ssh协议进行远程拷贝
    - rsync: 既可以使用rsync协议也可以使用ssh协议
             使用ssh协议指定端口：rsync -rvz --progress -e 'ssh -p 22'

21. 使用cygwin的ssh服务器
    1、配置cygwin
        需要的软件包：cygrunsrv、openssh ~
        管理员身份运行cygwin
        $ ssh-host-config               #引导ssh服务配置 ~
>
        *** Query: Should StrictModes be used? (yes/no)                         #输入yes
        *** Query: Should privilege separation be used? (yes/no)                #输入yes
        *** Query: Do you want to install sshd as a service?
        *** Query: (Say "no" if it is already installed as a service) (yes/no)  #输入yes
        *** Query: Enter the value of CYGWIN for the daemon: []                 #输入ntsec
        *** Info: This script plans to use 'cyg_server'.
        *** Info: 'cyg_server' will only be used by registered services.
        *** Query: Do you want to use a different name? (yes/no)                #输入no
        *** Query: Please enter the password for user 'cyg_server':             #输入密码
        *** Query: Create new privileged user account 'PC\cyg_server'
                   (Cygwin name: 'cyg_server')? (yes/no)                        #输入yes
        *** Query: Reenter:                                                     #输入密码
        *** Info: The sshd service has been installed under the 'cyg_server'
        *** Info: account.  To start the service now, call `net start sshd' or
        *** Info: `cygrunsrv -S sshd'.  Otherwise, it will start automatically
        *** Info: after the next reboot.
        *** Info: Host configuration finished. Have fun!
<
        $ net start sshd                #启动SSH服务~
        $ mkpasswd -l > /etc/passwd     #使用windows用户的密码 ~
        $ mkgroup -l > /etc/group       #使用windows用户组 ~
        NOTE: 可以在windows服务里找到"CYGWIN sshd"的服务
        NOTE: /etc/sshd_config 内包含sshd的详细配置（可修改默认端口号等），修改后重启ssh服务
        NOTE: ~/.ssh/config 内包含客户端的配置
        NOTE: 别的有用的命令：
              `$ net stop sshd  #关闭服务，用于重启`
              `$ sc delete sshd #删除服务，用于重装`
    2、开放windows的22端口 (SSH使用端口)
       防火墙中设置允许22端口入栈, window防火墙为例： >
       入栈规则->新建规则->规则类型(选择"端口")->TCP,22->允许连接
<    3、客户端远程操作： >
       $ ssh server@192.168.1.123  #使用服务器端的用户名密码
<    4、客户端不用每次都再输入密码 (密钥认证)： >
       $ ssh-keygen                        #创建密码，一路回车
       $ ssh-copy-id server@192.168.1.123  #拷贝密码到服务器 或者拷贝客户端的id_rsa.pub文件的内容到服务器的.ssh/authorized_keys内
       NOTE: 确保服务器的 ~/.ssh的权限是700，~/.ssh/authorized_keys的权限是600
<    5、查看或踢出已经登录的用户： >
       $ sudo w -f            #查看登录用户
       $ pkill -kill -t pts1  #踢出登录用户，或者 $ pkill -9 -t pts1 强制踢出

22. 使用ssh正向连接、反向连接、做socks代理的方法

    用ssh做正向连接 (LocalForward) ~
    说明： client连上server，然后把server能访问的机器地址和端口（当然也包括server自己）镜像到client的端口上。
    命令： `$ ssh -L [客户端IP或省略:][客户端端口]:[服务器侧能访问的IP:][服务器侧能访问的IP的端口] 登陆服务器的用户名@服务器IP -p [服务器ssh服务端口(默认22)]`
           其中，客户端IP可以省略，省略的话就是127.0.0.1了，也就是说只能在客户端本地访问。服务器IP都可以用域名来代替。
    举例： >
           你的IP是192.168.1.2，你可以ssh到某台服务器8.8.8.8，8.8.8.8可以访问8.8.4.4，你内网里还有一台机器可以访问你。
           如果你想让内网里的另外一台电脑访问8.8.4.4的80端口的http服务，那么可以执行：
           ssh -L 192.168.1.2:8080:8.8.4.4:80 test@8.8.8.8 (config: `LocalForward: 192.168.1.2:8080 8.8.4.4:80`)
           也就是说，ssh到8.8.8.8上，然后让8.8.8.8把8.8.4.4的80端口映射到本地的8080端口上，而且和本地192.168.1.2这个IP绑定。
           内网里的另外一台机器可以通过IE浏览器中输入http://192.168.1.2:8080查看8.8.4.4的网页。
           当然，如果是其他服务，比如ftp、ssh、远程桌面也是可以的。不过，VPN貌似是不行的，可能是因为GRE协议无法通过。
<
    用ssh做反向连接 (RemoteForward) ~
    说明： client连上server，然后把client能访问的机器地址和端口（也包括client自己）镜像到server的端口上。
           反向连接用得可能更多一些。比如你的客户端在内网，在外网是无法直接访问到的，这时用反向连接打通一条隧道，就可以从外网通过这条隧道进来了。
    命令： `$ ssh -R [服务器IP或省略:][服务器端口]:[客户端侧能访问的IP:][客户端侧能访问的IP的端口] 登陆服务器的用户名@服务器IP -p [服务器ssh服务端口(默认22)]`
           其中，服务器IP如果省略，则默认为127.0.0.1，只有服务器自身可以访问。指定服务器外网IP的话，任何人都可以通过[服务器IP:端口]来访问服务。
           当然，这个时候服务器本机也要输入外网IP:端口来访问。
    举例： >
           你的IP是192.168.1.2，你可以ssh到外网某台服务器8.8.8.8，你内网里有一台机器192.168.1.3。
           如果你想让外网所有的能访问8.8.8.8的IP都能访问192.168.1.3的http服务，那么可以执行：
           ssh -R 8.8.8.8:8080:192.168.1.3:80 test@8.8.8.8 (config: `RemoteForward: 8.8.8.8:8080 192.168.1.3:80`)
           也就是说，ssh到8.8.8.8上，然后把本地局域网内192.168.1.3的80端口映射到8.8.8.8的8080端口上，
           这样外网任何一台可以访问8.8.8.8的机器都可以通过8080端口访问到内网192.168.1.3机器的80端口了。
           反向连接同样支持各种服务。
<
    用ssh做socks代理 (正向:DynamicForward, 反向:RemoteForward) ~
    说明： 假设你内网里某台机器可以上网，但是你不能上网，如果你有ssh到那台机器的权限，那么就可以利用ssh方式建立一个代理socks5，通过代理来上网。
    命令： `$ ssh -D [本地IP或省略:][本地端口] 登陆服务器的用户名@服务器IP -p [服务器ssh服务端口(默认22)]`
           道理和上面是一样的，执行这个命令之后，本地会监听指定的端口等待连接。
           在配置代理的时候直接选择Sock5就可以了，不需要用户名和密码验证。
           windows系统代理配置方法：Internet选项->连接->局域网设置：勾选为LAN使用代理服务器，然后任何字段都不要填，点“高级”按钮，在套接字里面填好相应的配置，其他都留空。
           一个叫做Sockscap的软件，把应用扔进去就能以代理的方式上网了。
           如果你想把socks代理转换成http代理，可以用privoxy这个东东。
    举例： >
           正向：ssh -D 1234 test@8.8.8.8 (config: `DynamicForward: 1234`)
           反向：ssh -R 1234 test@8.8.8.8 (config: `RemoteForward: 1234`)


23. tmux
    架构:
        ┌Server
        │   ┌Session1
        │   │   ┌Window1
        │   │   │   ┌Pane1
        │   │   │   ├Pane2
        │   │   │   ├Pane3
        │   │   │   └···
        │   │   ├Window2
        │   │   ├Window3
        │   │   └···
        │   ├Session2
        │   ├Session3
        └   └···

        启动一个tmux之后就会自动启动一个Server (当Server下没有任何Session后，该Server就会退出，也可以通过：`tmux kill-server`退出)，
        这个Server下可以有很多个Session(会话/工作台，通过：`tmux new`创建， `tmux ls`列出，`tmux atach -t xxx`进入，`tmux detach`挂起，`tmux kill-session -t xxx`退出)，
        每个Session下又可以有很多个window(窗口)，
        每个window下又可以有很多pane(子窗口/小窗口)

    注意：
        1、启动tmux server是很慢的，所以别总是直接退出session(退出shell(Ctrl-D)也会直接退出session的)，常用`tmux detach`和`tmux atach`
        2、使用tmuxinator时，最好tmux server已经启动了，否则启动tmuxinator非常慢
        3、tmuxinator的自定义layout可以在已经手动layout之后使用 `tmux list-windows` 显示，pane编号使用 `Ctrl-b q` 显示

    快捷键: >
                    Ctrl+b      激活控制台；此时以下按键生效
        系统操作    ?           列出所有快捷键；按q返回
                    d           脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话
                    D           选择要脱离的会话；在同时开启了多个会话时使用
                    Ctrl+z      挂起当前会话
                    r           强制重绘未脱离的会话
                    s           选择并切换会话；在同时开启了多个会话时使用
                    :           进入命令行模式；此时可以输入支持的命令，例如kill-server可以关闭服务器
                    [           进入复制模式；此时的操作与vi/emacs相同，按q/Esc退出
                    ~           列出提示信息缓存；其中包含了之前tmux返回的各种提示信息
        窗口操作    c           创建新窗口
                    &           关闭当前窗口
                    数字键      切换至指定窗口
                    p           切换至上一窗口
                    n           切换至下一窗口
                    l           在前后两个窗口间互相切换
                    w           通过窗口列表切换窗口
                    ,           重命名当前窗口；这样便于识别
                    .           修改当前窗口编号；相当于窗口重新排序
                    f           在所有窗口中查找指定文本
                    z           最大化当前窗口 / 恢复窗口
        面板操作    ”           将当前面板平分为上下两块
                    %           将当前面板平分为左右两块
                    x           关闭当前面板
                    !           将当前面板置于新窗口；即新建一个窗口，其中仅包含当前面板
                    Ctrl+方向键 以1个单元格为单位移动边缘以调整当前面板大小
                    Alt+方向键  以5个单元格为单位移动边缘以调整当前面板大小
                    Space       在预置的面板布局中循环切换；依次包括even-horizontal、even-vertical、main-horizontal、main-vertical、tiled
                    q           显示面板pane编号
                    o           在当前窗口中选择下一面板
                    方向键      移动光标以选择面板
                    {           向前置换当前面板
                    }           向后置换当前面板
                    Alt+o       逆时针旋转当前窗口的面板
                    Ctrl+o      顺时针旋转当前窗口的面板
<
    我的TMUX快捷键： >
                    ctrl-d      Detach session
                    | -         Split window
                    ctrl-b      Split window
                    > <         Window movement
                    h l j k     Pan movement
                    tab         Pan movement
                    R           Reload ~/.tmux.conf
                    ctrl-v      Capture pane and open with vim
                    m           Toggle mouse mode
                    + -         Zoom pane to full screen, Restore

24. aria2c 下载工具
    下载:
        aria2c url
        aria2c 'xxx.torrnet'
        aria2c '磁力链接'

    恢复下载：
        aria2c -c url

    列出种子内容:
        aria2c -S target.torrent

    下载种子内编号为 1、4、5、6、7 的文件:
        aria2c –select-file=1,4-7 a.torrent

    下载磁力链接的种子文件:
        aria2c --bt-metadata-only=true --bt-save-metadata=true 'magnet:?xtxxxx'

    需要cookies验证(Chrome插件: 'cookie.txt export'):
        aria2c –load-cookies=cookie_file url

    限速下载:
        单个文件最大下载速度： aria2c –max-download-limit=300K
        整体下载最大速度： aria2c –max-overall-download-limit=300k

    其他常用选项:
        -x 最大的链接线程数
        -j 最大下载的文件个数
        -o 重命名下载的文件

25. 批量重命名文件
    perl版本的rename： >
    rename 's/\.txt$/.a/' *  #把当前文件夹下所有后缀是txt的文件替换成后缀是a

26. 常用小工具
    软件开发:
        ldd             Print shared library dependencies (可执行文件，库)
        nm              List symbols in files (库)
        size            Displays the sizes of sections inside binary files
        objdump         Display information from object files
        addr2line       Convert addresses into line number/file name pairs
        strings         Display printable strings in files
        gprof           display call graph profile data
        strip           Removes symbols and sections from files
    其他：
        ps              Report process status
        date            Display the current time in the given FORMAT, or set the system date.
        cal             Display a calendar
        hexdump         Display file contents in hexadecimal, decimal, octal, or ascii
        ascii           Prints all aliases of an ASCII character
        md5sum          Print or check MD5 (128-bit) checksums.
        sha1sum         Print or check SHA1 (106-bit) checksums.
        sha256sum       Print or check SHA256 (256-bit) checksums.
        sha512sum       Print or check SHA512 (512-bit) checksums.
        tree            List contents of directories in a tree-like format.
        tty             Print the file name of the terminal connected to standard input.
        type            Indicate how each name would be interpreted if used as a command name.
        whereis         locate the binary, source, and manual page files for a command
        wc              Print newline, word, and byte counts for each FILE
        time            检查命令执行时间
        column          输出个数成列表格：cat /etc/passwd | column -t -s:
        fzf             a command line fuzzy finder

27. X Window System (Cygwin)
    请求的包： >
        xorg-server, xinit，xhost(远程登录时)
<    启动X Window： >
        $ startxwin                  # 启动X Window System，此时系统的状态栏会出现x window的图标
        $ man xwin                   # 查看xwin的帮助
        $ man startxwin              # 查看startxwin的帮助
<    本地控制台连接到本地Xserver： >
        $ export DISPLAY=:Num.0      # export DISPLAY=:0.0，Num指当前连接的server (如：/tmp/.X11-unix/X0，/tmp/.X11-unix/X1，...)
<    通过ssh远程访问Xserver：(ssh登录后执行如下) >
        $ export DISPLAY=Host:Num.0  # export DISPLAY=172.25.151.1:0.0，Host指client的主机名或者IP地址
        $ xhost +                    # 任何Host都可以显示图形了


28. 包管理 apt / dpkg
    apt-get:
        sudo apt-get install package                安装包
        sudo apt-get install package --reinstall    重新安装包  
        sudo apt-get -f install                     修复安装"-f = ——fix-missing"  
        sudo apt-get remove package                 删除包  
        sudo apt-get remove package --purge         删除包，包括删除配置文件等  
        sudo apt-get autoremove package             删除包及其依赖的软件包  
        sudo apt-get update                         更新源  
        sudo apt-get upgrade                        更新已安装的包  
        sudo apt-get dist-upgrade                   升级系统  
        sudo apt-get dselect-upgrade                使用 dselect 升级  
        sudo apt-get build-dep package              安装相关的编译环境  
        sudo apt-get source package                 下载该包的源代码  
        sudo apt-get clean && sudo apt-get autoclean 清理无用的包  
        sudo apt-get check                          检查是否有损坏的依赖  

    apt-cache (用于搜索包)：
        sudo apt-cache search package               搜索包  
        sudo apt-cache show package                 获取包的相关信息，如说明、大小、版本等  
        sudo apt-cache showpkg package              显示软件包信息，包括包的依赖关系，包的提供者，   
        sudo apt-cache pkgnames                     打印软件包列表中所有包的名字  
        sudo apt-cache dumpavail                    打印软件包列表中所有包的简介信息  
        sudo apt-cache depends package              了解使用依赖  
        sudo apt-cache rdepends package             是查看该包被哪些包依赖

    dpkg (安装离线下载的软件包 *.deb)
        dpkg –l | grep package 查询deb包的详细信息，没有指定包则显示全部已安装包  
        dpkg -s package 查看已经安装的指定软件包的详细信息  
        dpkg -L package 列出一个包安装的所有文件清单  
        dpkg -S file 查看系统中的某个文件属于哪个软件包  
        dpkg -i 所有deb文件的安装  
        dpkg -r 所有deb文件的卸载  
        dpkg -P 彻底的卸载，包括软件的配置文件  
        dpkg -c 查询deb包文件中所包含的文件  
        dpkg -L 查看系统中安装包的的详细清单，同时执行 -c

29. Cygwin上添加新用户 (like Linux 'adduser'):
    $ net user NewUserName NewUserPassword /add /yes        # add user
    $ net localgroup <an_local_group> NewUserName /add      # add user with group
    $ passwd NewUserName                                    # change user password
    $ mkpasswd -l -u NewUserName >> /etc/passwd              # add it to etc

30. Linux搭建git服务器
    创建git用户
        adduser git
    创建证书登录:
        收集所有需要登录的用户的公钥，就是他们自己的id_rsa.pub文件，
        把所有公钥导入到/home/git/.ssh/authorized_keys文件里，一行一个。
    创建git库
        sudo git init --bare sample.git
        sudo chown -R git:git sample.git
    禁用shell登录
        修改/etc/passwd的git用户的shell为/usr/bin/git-shell
    客户端clone:
        git clone git@serverIP:/gitsrv/sample.git

31. 启动cygserver,以优化系统性能
    管理员身份运行：
    $ cygserver-config
    $ cygrunsrv -S cygserver

32. 源码编译时 安装文件到指定路径 (DESTDIR绝对目录, prefix相对目录(相对于DESTDIR))
    make install DESTDIR=/install/directory prefix=/usr

33. ss/ssr/v2ray/socks5 透明代理 [https://www.zfl9.com/ss-redir.html]

    先说 ss/ssr 透明代理吧，ss-redir 是 ss-libev[https://github.com/shadowsocks/shadowsocks-libev]、
    ssr-libev[https://github.com/shadowsocksr-backup/shadowsocksr-libev] 中的一个工具，配合 iptables
    可以在 Linux 上实现 ss、ssr 透明代理，ss-redir 的 TCP 透明代理是通过 REDIRECT 方式实现的，而 UDP
    透明代理是通过 TPROXY 方式实现的。强调一点，利用 ss-redir 实现透明代理必须使用 ss-libev 或
    ssr-libev，python、go 等版本没有 ss-redir、ss-tunnel 程序。

    当然，ss、ssr 透明代理并不是只能用 ss-redir 来实现，使用 ss-local + redsocks2/tun2socks 同样可以
    实现 socks5（ss-local 是 socks5 服务器）全局透明代理；ss-local + redsocks2 实际上是 ss-redir
    的分体实现，TCP 使用 REDIRECT 方式，UDP 使用 TPROXY 方式；ss-local + tun2socks 则相当于 Android
    版 SS/SSR 的 VPN 模式，因为它实际上是通过一张虚拟的 tun 网卡来进行代理的。

    最后说一下 v2ray 的透明代理，其实原理和 ss/ssr-libev 一样，v2ray 可以看作是 ss-local、ss-redir、
    ss-tunnel、ss-server 四者的合体，因为同一个 v2ray 程序既可以作为 server 端，也可以作为 client 端。
    所以 v2ray 的透明代理也有两种实现方式，一是利用对应的 ss-redir/ss-tunnel + iptables，二是利用对应的
    ss-local + redsocks2/tun2socks（redsocks2/tun2socks 可以与任意 socks5 代理组合，实现透明代理）。

    组件区别
    ss-server
    shadowsocks 服务端程序，核心部件之一，各大版本均提供 ss-server 程序。

    ss-local
    shadowsocks 客户端程序，核心部件之一，各大版本均提供 ss-local 程序。
    ss-local 是运行在本地的 socks5 代理服务器，根据 OSI 模型，socks5 是会话层协议，支持 TCP 和 UDP 的代理。

    但是现在只有少数软件直接支持 socks5 代理协议，绝大多数都只支持 http 代理协议。好在我们可以利用 privoxy
    将 socks5 代理转换为 http 代理，使用 privoxy 还有一个好处，那就是可以实现 gfwlist 分流模式（不过现在的
    ss-tproxy 脚本也可以了），如果你对它感兴趣，可以看看 ss-local 终端代理[https://www.zfl9.com/ss-local.html]。

    ss-redir
    shadowsocks-libev 提供的socks5 透明代理工具，也就是今天这篇文章的主题 - 实现透明代理！

    正向代理
    正向代理，即平常我们所说的代理，比如 http 代理、socks5 代理等，都属于正向代理。
    正向代理的特点就是：如果需要使用正向代理访问互联网，就必须在客户端进行相应的代理设置。

    透明代理
    透明代理和正向代理的作用是一样的，都是为了突破某些网络限制，访问网络资源。
    但是透明代理对于客户端是透明的，客户端不需要进行相应的代理设置，就能使用透明代理访问互联网。

    反向代理
    当然，这个不在本文的讨论范畴之内，不过既然提到了前两种代理，就顺便说说反向代理。
    反向代理是针对服务端来说的，它的目的不是为了让我们突破互联网限制，而是为了实现负载均衡。

    举个栗子：
    ss-local 提供 socks5 正向代理，要让软件使用该代理，必须对软件进行相应的代理配置，否则不会走代理；
    ss-redir 提供 socks5 透明代理，配置合适网络规则后，软件会在不知情的情况下走代理，不需要额外配置。

    ss-tunnel
    shadowsocks-libev 提供的本地端口转发工具，通常用于解决 dns 污染问题。

    假设 ss-tunnel 监听本地端口 53，转发的远程目的地为 8.8.8.8:53；系统 dns 为 127.0.0.1。
    去程：上层应用请求 dns 解析 -> ss-tunnel 接收 -> ss 隧道 -> ss-server 接收 -> 8.8.8.8:53；
    回程：8.8.8.8:53 响应 dns 请求 -> ss-server 接收 -> ss 隧道 -> ss-tunnel 接收 -> 上层应用。

    方案说明
    用过 Linux SS/SSR 客户端（尤其指命令行界面）的都知道，它们比 Windows/Android 中的 SS/SSR 客户端难用多了，
    安装好就只有一个 ss-local（libev 版还有 ss-redir、ss-tunnel，但我相信大部分人装得都是 python 版的），
    启动 ss-local 后并不会像 Windows/Android 那样自动配置系统代理，此时它仅仅是一个本地 socks5 代理服务器，
    默认监听 127.0.0.1:1080，如果需要利用该 socks5 代理上外网，必须在命令中指定对应的代理，
    如 curl -4sSkL -x socks5h://127.0.0.1:1080 https://www.google.com。

    但我想大部分人要的代理效果都不是这种的，太原始了。那能不能配置所谓的“系统代理”呢，可以是可以，
    但是好像只支持 http 类型的代理，即在当前 shell 中设置 http_proxy、https_proxy 环境变量，假设存在
    一个 http 代理（支持 CONNECT 请求方法），监听地址是 127.0.0.1:8118，可以这样做：
    export http_proxy=http://127.0.0.1:8118; export https_proxy=$http_proxy。执行完后，git、curl、wget
    等命令会自动从环境变量中读取 http 代理信息，然后通过 http 代理连接目的服务器。

    那问题来了，ss-local 提供的是 socks5 代理，不能直接使用怎么办？也简单，Linux 中有很多将 socks5 包装为
    http 代理的工具，比如 privoxy。只需要在 /etc/privoxy/config 里面添加一行 forward-socks5 / 127.0.0.1:1080 .，
    启动 privoxy，默认监听 127.0.0.1:8118 端口，注意别搞混了，8118 是 privoxy 提供的 http 代理地址，
    而 1080 是 ss-local 提供的 socks5 代理地址，发往 8118 端口的数据会被 privoxy 处理并转发给 ss-local。
    所以我们现在可以执行 export http_proxy=http://127.0.0.1:8118; export https_proxy=$http_proxy 来配置
    当前终端的 http 代理，这样 git、curl、wget 这些就会自动走 ss-local 出去了。

    当然我们还可以利用 privoxy 灵活的配置，实现 Windows/Android 中的 gfwlist 分流模式。gfwlist.txt 其实是
    对应的 Adblock Plus 规则的 base64 编码文件，显然不能直接照搬到 privoxy 上。这个问题其实已经有人解决了，
    利用 snachx/gfwlist2privoxy python 脚本就可轻松搞定。但其实我也重复的造了一个轮子：zfl9/gfwlist2privoxy，
    我并不是吃饱了没事干，是因为我当时运行不了他的脚本（也不知道什么原因），所以花了点时间用 shell 脚本实现
    了一个 gfwlist2privoxy（但其实我是用 perl 转换的，只不过用 shell 包装了一下）。脚本转换出来的是一个
    gfwlist.action 文件，我们只需将该 gfwlist.action 文件放到 /etc/privoxy 目录，然后在 config 中添加一行
    actionsfile gfwlist.action（当然之前 forward-socks5 那行要注释掉），重启 privoxy 就可以实现 gfwlist 分流了。

    但仅仅依靠 http_proxy、https_proxy 环境变量实现的终端代理效果不是很好，因为有些命令根本不理会你的
    http_proxy、https_proxy 变量，它们依旧走的直连。但又有大神想出了一个巧妙的方法，即 rofl0r/proxychains-ng，
    其原理是通过 LD_PRELOAD 特殊环境变量提前加载指定的动态库，来替换 glibc 中的同名库函数。这个 LD_PRELOAD
    指向的其实就是 proxychains-ng 实现的 socket 包装库，这个包装库会读取 proxychains-ng 的配置文件（这里面配
    置代理信息），之后执行的所有命令调用的 socket 函数其实都是 proxychains-ng 动态库中的同名函数，于是就实现
    了全局代理，而命令对此一无所知。将 proxychains-ng 与 privoxy 结合起来基本上可以完美实现 ss/ssr 的本地全局
    gfwlist代理（小技巧，在 shell 中执行 exec proxychains -q bash 可以实现当前终端的全局代理，如果需要每个终端
    都自动全局代理，可以在 bashrc 文件中加入这行）。

    但是很多人对此依然无法满足，因为他们想实现 OpenWrt 那种路由级别的全局透明代理（并且还有 gfwlist、绕过大陆
    地址段这些分流模式可选择），这样只要设备连到 WiFi 就能直接无缝上网，完全感觉不到“墙”的存在。如果忽略分流
    模式（即全部流量都走代理出去），那么实现是很简单的（几条 iptables 就可以搞定，但是这太简单粗暴了，很多国
    内网站走代理会非常慢，体验很不好）；但是如果要自己实现 gfwlist、绕过大陆地址段这些模式，恐怕很多人都会望
    而却步，因为确实复杂了一些。但这种透明代理的模式的确很诱人，毕竟只要设置一次就可以让所有内网设备上 Internet，
    所以我开始摸索如何在 Linux 软路由中（我用的是树莓派 3B，目前还凑合，当然也可以直接在 Windows 中利用 
    VMware/VirtualBox 建一个桥接模式的虚拟机，做所谓的 代理网关）实现类似 OpenWrt 的代理模式，而我摸索出来的
    成果就是 ss-tproxy 透明代理脚本。

    ShadowsocksR
    ShadowsocksR（简称 SSR）是由 @breakwa11 发起的一个 Shadowsocks 分支，主要特点是增加了协议插件（增强安全性）
    和混淆插件（降低识别率），虽然 breakwa11 早在 2017 年 7 月就已经删除了 SSR 相关源码，但我目前仍然使用的 SSR
    （V2Ray 速度不行，我的树莓派 3B 完全带不起），自写了一个 C 语言版的 v2ray，即 tls-proxy，用在树莓派上完全没
    问题，速度与 ss/ssr-libev 基本没区别。因为原版 SS 被 QoS（Quality of Service，服务质量）影响严重
    （SS + simple-obfs 也能像 SSR 那样混淆），如果不将流量伪装为 HTTP/HTTPS 数据，那么代理的速度很难提上来
    （即使装了锐速、BBR 魔改）。为什么呢，因为 HTTP/HTTPS 流量的优先级相对来说是比较高的（标准端口，HTTP/80、HTTPS/443），
    优先级高的包在国际出口上就会先发送，尽量不滞留，路顺畅了速度自然就上来了。

    SSR 混淆说明
    ## Client -> Server 方向
    客户端请求 -> ss-local -> 协议插件 -> 加密 -> 混淆插件
    x======================== GFW =======================
    混淆插件 -> 解密 -> 协议插件 -> ss-server -> 目标服务器
    ## 协议插件与混淆插件的作用
    "协议插件": 主要用于增加数据完整性校验，增强安全性，进行包长度混淆等
    "混淆插件": 主要用于伪装为其它协议（如 HTTP、HTTPS），扰乱 GFW 的检测
    ## 推荐的协议插件与混淆插件
    协议插件: "auth_sha1_v4"、"auth_aes128_md5"、"auth_aes128_sha1"、"auth_chain_a"
    混淆插件: "plain"（即：不混淆）、"http_simple"、"http_post"、"tls1.2_ticket_auth"
    # 为什么推荐 plain，因为混淆不总是有效果的，有时候不混淆让其看起来像随机数据会更好一些

34. fstab (/etc/fstab)
    cygwin:
        //192.168.5.11/file_huntersun       /mnt/5p11   smbfs binary,noacl 0 0
        sshfs#u0_a103@192.168.100.230:dir   /mnt/mate9  fuse  defaults,user,allow_other,reconnect,ConnectTimeout=5,ServerAliveInterval=5,port=9000 0 0
    WSL:
        //192.168.5.10/huntersun            /mnt/5p10   drvfs  defaults  0  0
    可能需要先创建mount点的文件夹：sudo mkdir /mnt/5p10

35. cron
    cygwin使用cron时，如果将cron作为windows服务来运行的话，会导致所有定时gui不显示窗口
    可以制作快捷方式：D:\cygwin64\bin\run.exe --quote /usr/bin/bash.exe -l -c "/usr/sbin/cron.exe" 放到“启动”中
    常用命令：
    $ crontab -e        编辑和查看表, 修改退出会自动生效
    $ cronevents        查看cron的log

36. Ubuntu查询某个命令数据哪个安装包
    aptitude search ping
    apt-file search ping

38. 使用nc做网络传输
    发送端：echo "something" | nc dest_ip dest_port
    接收端：nc local_port
    例如网络串口: >
    发送本地串口数据到192.168.101.141
        picocom /dev/ttyS4 -b 115200 | pp | tee --output-error=warn $(tty) | nc 192.168.101.141 11223
    192.168.101.141接收网络串口数据:
        nc -k -l 11223

39. 源码编译：
    Cygwin:
        cygport (cygwin编译安装打包工具):
            安装cygport：
                $ apt-cyg install cygport       #安装cygport
            使用：
                $ cygport gdb.cygport prep      #准备
                $ cygport gdb.cygport compile   #编译
                $ cygport gdb.cygport install   #安装
                $ cygport gdb.cygport package   #打包

        universal-ctags:
            github:
                $ git clone https://github.com/universal-ctags/ctags.git
            dependence：
                $ apt-cyg install mingw64-i686-gcc-core
                $ apt-cyg install mingw64-i686-win-iconv
            修改mk_mingw.mak：
                DEFINES下加入 "-DUNIX_PATH_SEPARATOR"
            command：
                make -f mk_mingw.mak  CC=i686-w64-mingw32-gcc

        YouCompleteMe:
            github:
                $ git clone https://github.com/Valloric/YouCompleteMe.git
                $ git submodule update --init --recursive
            dependence:
                $ apt-cyg install libboost-devel
                $ apt-cyg install libboost_python3-devel
                $ apt-cyg install python3-devel
                $ apt-cyg install libclang-devel
            command:
                $ python3 install.py --clang-completer --system-libclang --system-boost
                $ find -name libclang.dll.a -delete  # 删除libclang.dll.a, 防止ycmd强制加载
            cleanup: >
                rm -rf azure
                rm -f azure-pipelines.yml codecov.yml COPYING.txt install.sh README.md tox.ini .coveragerc .ycm_extra_conf.py
                rm -f CODE_OF_CONDUCT.md CONTRIBUTING.md install.py print_todos.sh run_tests.py .mergify.yml

                find -iname '.git*' -exec rm -rf {} \;

                find -type d -iname '__pycache__' -exec rm -rf {} \;

                for n in 'doc' 'docs' '*test*' 'examples' '_appveyor' ; do
                    find third_party -type d -iname "$n" -exec rm -rf {} \;
                done

                for n in '.coveragerc' '.hgignore' '.hgtags' 'appveyor.yml' 'codecov.yml' 'makefile' 'cmakelists.txt' \
                        'contributors' 'license*' 'authors*' 'changes*' 'changelog*' 'readme*' 'manifest' '.travis.yml' \
                        '*.txt' '*.rst' '*.go' '*.svg' '*.ai' '*.md' '*.in' '*.cmake' '*.bat' '*.sh' '*.c' '*.h' '*.inc' \
                        '*.cc' '*.cpp' '*.hpp' '*.ipp' '*.cs' '*.csproj' '*.sln' 'libclang.dll.a' ; do
                    find third_party -type f -not -iname '*.py' -not -iname 'grammar*' -iname "$n" -delete
                done

                find -depth -type d -empty -delete
<
        arm-none-eabi-gdb:
            最新版本在：
                ftp://sourceware.org/pub/gdb/releases/
            原始cygwin版本下载：
                $ apt-cyg source gdb
                修改下载的gdb源文件的gdb.cygport:
                    src_compile()内的cygconf中，加入：--target arm-none-eabi
                                                删除：--with-system-readline
                    删除PATCH_URI里的内容
                用最新版本的gdb替换.tar.xz文件
            使用cygport编译安装
            编译依赖：libexpat-devel liblzma-devel libmpfr-devel libncurses-devel libreadline-devel python2 python2-devel zlib-devel
            执行依赖: bash cygwin libexpat1 libgcc1 libiconv2 libintl8 liblzma5 libmpfr6 libncursesw10 libreadline7 libstdc++6 python27 zlib0

        vim:
            $ make distclean
            cd src
            $ ./configure --with-features=huge \
                          --enable-multibyte \
                          --enable-pythoninterp=yes \
                          --enable-python3interp=yes \
                          --enable-rubyinterp=yes \
                          --enable-perlinterp=yes \
                          --enable-luainterp=yes \
                          --enable-cscope \
                          --enable-fail-if-missing
            $ make
            $ make install

        tmux:
            tmux在cygwin上启动慢的解决方法：
            - 在server.c的server_start()函数的exit(0)的上一行添加：unlink(socket_path); 来删除已存在的socket文件
              $ ./autogen.sh && ./configure
              $ make
              $ make install DESTDIR=dist prefix=/usr

        sshfs:
            下载WinFsp并安装: https://github.com/billziss-gh/winfsp/releases
            在Cygwin下执行这个脚本："%ProgramFiles(x86)%\WinFsp\opt\cygfuse\install.sh
            下载sshfs：https://github.com/libfuse/sshfs/releases
            安装依赖：$ apt-cyg install libglib2.0-devel meson
            在sshfs源代码目录执行：$ ./test/appveyor-build.sh; ninja install
            eg: sshfs -o allow_other,reconnect,delay_connect,ConnectTimeout=5,ServerAliveInterval=5,port=9000,uid=-1,gid=-1,FileInfoTimeout=-1 u0_a103@192.168.100.230:storage/downloads/1 /mnt/mate9

    Ubuntu:
        Building from source:
            Install the tools if required: ~
                $ sudo apt-get install build-essential fakeroot dpkg-dev
                    - The build-essential package will make sure tools like gcc and make are installed.
                    - The fakeroot package allows users to create archives (in this case .deb) with files in them with root permissions and ownership.
                    - The dpkg tools are required for extracting the source and building the package.
            Make a directory for your build: ~
                $ mkdir vim-gtk3
                $ cd vim-gtk3
            Fetch the source: ~
                $ sudo apt-get source vim-gtk3      # 获取vim的源文件, 配置规则和选项：debian/rules
                $ sudo apt-get build-dep vim-gtk3   # 安装vim的build依赖
            Extract the source and patch it using the diff file: ~
                $ dpkg-source -x vim_xxx.dsc
            Build the source file: ~
                $ dpkg-buildpackage -rfakeroot -b    # WSL: dpkg-buildpackage -rsudo -b
                    这样会自动完成所有从源代码包构建二进制包的工作，包括以下几个步骤：
                    0、清理源代码树(debian/rules clean)
                    1、构建源代码包(dpkg-source -b)
                    2、构建程序(debian/rules build)
                    3、构建二进制包(fakeroot debian/rules binary)
                    4、使用 gpg 签署 .dsc 文件
                    5、使用 dpkg-genchanges 和 gpg 创建并签署上传用的 .changes 文件


        arm-none-eabi-gdb:
            最新版本在：
                ftp://sourceware.org/pub/gdb/releases/

            修改gdb/config.h中的PKGVERSION为："(GNU Arm Embedded Toolchain, Modified by liqiang in 20200609) "
            ../gdb-9.1/configure --target arm-none-eabi --enable-tui --disable-gdbtk --with-expat --with-lzma --with-mpfr --with-python --enable-sim

        vim:
            $ sudo apt-get build-dep vim-gtk3
            $ make distclean
            $ cd src
            $ ./configure --with-features=huge \
                          --enable-gui=gtk3 \
                          --enable-multibyte \
                          --enable-pythoninterp=yes \
                          --enable-python3interp=yes \
                          --enable-fail-if-missing
                          # --enable-rubyinterp=yes \
                          # --enable-perlinterp=yes \
                          # --enable-luainterp=yes \
            $ make
            $ make install

40. Window10的Linux子系统
    Ubuntu 18.04
    a. 使用wsltty作为控制台
        https://github.com/mintty/wsltty
        安装位置：
            %LOCALAPPDATA%\wsltty
        wsltty使用.minttyrc:
            wsltty同样使用mintty的配置文件, 位置在: %APPDATA%\wsltty\config,
            把.minttyrc里的内容拷贝到这个文件中
        执行默认shell的快捷方式：
             %LOCALAPPDATA%\wsltty\bin\mintty.exe --WSL= --configdir="%APPDATA%\wsltty" -~ wsl.exe

    b. 使用国内源：
        $ vim /etc/apt/sources.list:
        $ sudo apt-get update
        $ sudo apt-get upgrade
        新源列表： >
            #ubunto 18.04
            deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
            deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
            deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
            deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
            deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
            deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
            deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
            deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
            deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
            deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse

            # Ubuntu 20.04
            # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释
            deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse
            # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse
            deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse
            # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse
            deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse
            # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse
            deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse
            # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse
            # 预发布软件源，不建议启用
            # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse
            # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse
<

    c. 修改默认shell为zsh
        $ chsh -s $(which zsh)
        上条命令如果不行，则在.bashrc的最前面添加：[[ -t 1 ]] && exec zsh
        快捷方式：%LOCALAPPDATA%\wsltty\bin\mintty.exe --WSL= --configdir="%APPDATA%\wsltty" -~ wsl.exe 会加载默认shell，否则会强制启动bash

    d. 添加新的用户
        $ useradd liqiang --shell /usr/bin/zsh --home-dir /home/liqiang -m
        $ passwd liqiang         # 新用户的密码
        $ sudo vim /etc/sudoers  # 使新用户具备sudo权限
            /etc/sudoers 添加如下内容： >
                liqiang ALL=(ALL) ALL
<        在Powershell中设置默认用户:
            $ ubuntu1804 config --default-user liqiang

41. WSL1
    a. Fixing WSL Mount Permissions
       https://www.turek.dev/post/fix-wsl-file-permissions/
       The short version is to add this section to your WSL instance’s /etc/wsl.conf
       (the file probably does not exist, just create it): >
        [automount]
        enabled = true
        options = "metadata,umask=22,fmask=11"
<       And then run: wsl --shutdown

    b. Ubuntu 20.04 不能执行sleep等函数
        https://github.com/microsoft/WSL/issues/4898#issuecomment-646790723
        Create this file called nanosleep.c >

        #include <time.h>
        #include <unistd.h>

        // This restores the old behaviour of nanosleep() to use CLOCK_MONOTONIC.
        //
        // "POSIX.1 specifies that nanosleep() should measure time against the
        // CLOCK_REALTIME clock. However, Linux measures the time using the
        // CLOCK_MONOTONIC clock.  This probably does not matter [...]"
        //
        // # gcc -shared -fPIC -o /usr/local/lib/libnanosleep.so nanosleep.c
        // # echo /usr/local/lib/libnanosleep.so >> /etc/ld.so.preload
        //
        int nanosleep(const struct timespec *req, struct timespec *rem)
        {
            return clock_nanosleep(CLOCK_MONOTONIC, 0, req, rem);
        }

        int usleep(useconds_t usec)
        {
            struct timespec req = {
                .tv_sec     = (usec / 1000000),
                .tv_nsec    = (usec % 1000000) * 1000,
            };
            return nanosleep(&req, NULL);
        }


42. WSL2

    WSL2 Kernel: https://docs.microsoft.com/en-us/windows/wsl/wsl2-kernel

    a. How to copy text from vim to system clipboard?
       https://github.com/Microsoft/WSL/issues/892 >

        For those who want to go the X server route, let me leave my notes here.

        1. Install VcXsrv(https://sourceforge.net/projects/vcxsrv/) (I found that Xming
           is outdated on sourceforge and the new version is donationware)
        2. If it starts after installing, stop it
        3. Start it using XLaunch (search in the start menu), go with all the defaults
           (ensure the clipboard options are checked)
        4. At the end, save the configuration to a file (use that to start it from now on)
        5. Put export DISPLAY=localhost:0.0 in your .bashrc in bash for Windows (and run the
           command in any open bash windows). The reason I explicitly say localhost is that
           this makes SSH X forwarding work, see below.
        6. Ensure vim is installed using clipboard support. vim --version | grep clipboard should
           say +clipboard, not -clipboard. Also if you run the ex command :echo has('clipboard')
           in vim and it says 0 it does not have clipboard support compiled in. If you don't have
           clipboard support, install the vim-gtk package (apt-get install vim-gtk).
        7. It should now work

        As a bonus you should now be able to copy from and to your Windows clipboard from a remote
        machine by using SSH X forwarding (ssh -X ... ). You can use xclip on the remote machine or
        if you use vim there you will again need to make sure the clipboard option is compiled into
        vim (e.g. install vim-gtk). You can probably also configure PuTTY to use your local X server
        in case you prefer using that for remote connections.
<
    b. 不能连接到window的port：
        防火墙问题, powershell中运行（管理员）：
            New-NetFirewallRule -DisplayName "WSL" -Direction Inbound  -InterfaceAlias "vEthernet (WSL)"  -Action Allow
            # powershell -Command "Set-NetFirewallProfile -DisabledInterfaceAliases \"vEthernet (WSL)\""

    c. 通过VcXsrv.exe显示GUI时，如果有如下错误提示： >
            Authorization required, but no authorization protocol specified
            E233: cannot open display
<        原因：
            vcxsrv.exe没有允许其接收所有IP地址，应如下：vcxsrv.exe -multiwindow -clipboard -nowgl -ac
            或者在Extra Settting时勾选：Disable access control

    d. 不能运行windows程序
        由于tmux导致WSL_INTEROP出错
            export WSL_INTEROP=/run/WSL/$(ls /run/WSL/|awk 'NR==1{print}')


43. arm-none-eabi-gdb 修改以支持KEIL的ARMCC：
    a. gdb\symtab.c的producer_is_realview()函数的arm_idents加入： >
        "Component: ARM Compiler",
<
    b. 修复gdb不能解析windows路径的问题:
        gdb/source.c文件中添加函数： >
            // FIX can't parse windows path issue {
            const char *fix_windows_path(const char *string)
            {
              static char string_fix[PATH_MAX];
              int i, j;
              bool prev_is_sep = false;
              for (i=0, j=0; i<PATH_MAX && string[i]; ++i)
              {
                if (string[i]=='\\' || string[i]=='/')
                {
                  if (!prev_is_sep)
                    string_fix[j++] = '/';
                  prev_is_sep = true;
                }
                else
                {
                  prev_is_sep = false;
                  string_fix[j++] = string[i];
                }
              }
              string_fix[j] = '\0';

              return string_fix;
            }
<
        在gdb/source.c文件的openp()函数的 “if ((opts & OPF_TRY_CWD_FIRST) || IS_ABSOLUTE_PATH (string))” 之前加入: >
            string = fix_windows_path(string);
<
        在gdb/source.c文件的symtab_to_filename_for_display()函数的 return symtab->filename; 修改为: >
            return fix_windows_path(symtab->filename);


44. 预加载so
    预加载so的两种方式：
    - 修改 "/etc/ld.so.preload" 配置文件，这种方法对配置修改之后运行的进程生效，而无法影响已经在运行的进程
    - 启动进程前设置 "LD_PRELOAD" 变量(如shell中执行LD_PREOAD=/lib64/inject.so ./myprocess)，则只对当前进程生效
    默认情况下进程创建的子进程也会继承LD_PRELOAD环境变量，而父进程可以在子进程初始化前修改子进程的环境变量，从而避免往子代传播。

    LD_PRELOAD可以影响程序的运行时的链接，它允许你定义在程序运行前优先加载的动态链接库，这个功能主要就是用来有选择性的载入不同动态链接库中的相同函数。

    通过这个环境变量，我们可以在主程序和其动态链接库的中间加载别的动态链接库，甚至覆盖正常的函数。

    进程在启动后，会按照一定顺序加载动态库：
    - 加载环境变量LD_PRELOAD指定的动态库
    - 加载文件/etc/ld.so.preload指定的动态库
    - 搜索环境变量LD_LIBRARY_PATH指定的动态库搜索路径
    - 搜索路径/lib64下的动态库文件

    以下面两种方法可以让LD_PRELOAD失效。
    - 通过静态链接。使用gcc的-static参数可以把libc.so.6静态链入执行程序中。但这也就意味着你的程序不再支持动态链接。
    - 通过设置执行文件的setgid/setuid标志。在有SUID权限的执行文件，系统会忽略LD_PRELOAD环境变量。也就是说，如果你有以root方式运行的程序，最好设置上SUID权限。

    经典实例：
        fakeroot：
            fakeroot 允许执行 mknod 这样需要 root 权限的程序而不会失败（虽然没有真正创建设备文件），所以被 buildroot 用于文件系统构建。
            fakeroot 通过 libfakeroot-0.so 篡改了 getuid 相关的函数
        catchsegv:
            catchsegv 能够捕捉断错误，并打印出 backtrace 从而方便辅助定位软件问题。
            catchsegv 通过 libSegFault.so 捕获 SIGSEGV 信号来获得 backtrace

    简单例子：
        random_num.c： >
            #include<stdio.h>
            #include<stdlib.h>
            #include<time.h>
            int main()
            {
                srand(time(NULL));
                int i =10;
                while(i--)
                    printf("%d\n",rand()%100);
                return0;
            }
<        我相信，它足够简单吧。我不使用任何参数来编译它，如下所示：
        $ gcc random_num.c -o random_num ~
        我希望它输出的结果是明确的：从 0-99 中选择的十个随机数字，希望每次你运行这个程序时它的输出都不相同。

        现在，让我们假装真的不知道这个可执行程序的出处。甚至将它的源文件删除，或者把它移动到别的地方  我们已不再需要它了。我们将对这个程序的行为进行重大的修改，而你并不需要接触到它的源代码，也不需要重新编译它。

        因此，让我们来创建另外一个简单的 C 文件：
        unrandom.c： >
            int rand()
            {
                return 42;
            }
<        我们将编译它进入一个共享库中。
        $ gcc-shared -fPIC unrandom.c -o unrandom.so ~
        因此，现在我们已经有了一个可以输出一些随机数的应用程序，和一个定制的库，它使用一个常数值 42 实现了一个 rand() 函数。
        现在 …… 就像运行 random_num 一样，然后再观察结果：
        LD_PRELOAD=$PWD/unrandom.so ./random_nums ~
        如果你想偷懒或者不想自动亲自动手（或者不知什么原因猜不出发生了什么），我来告诉你  它输出了十次常数 42。

        如果先这样执行
        export LD_PRELOAD=$PWD/unrandom.so ~
        然后再以正常方式运行这个程序，这个结果也许会更让你吃惊：一个未被改变过的应用程序在一个正常的运行方式中，看上去受到了我们做的一个极小的库的影响 ……


45. bash 和 zsh 启动流程：
    Login Shells, Interactive Shells: (https://docstore.mik.ua/orelly/unix3/upt/ch03_04.htm)
        - Interactive shell:        An interactive shell reads commands from user input on a tty.
        - Non-interactive shell:    a shell reads commands from a file: a shell script
        - Login shell:              Typically, most users will encounter a login shell only if either:
            -- they logged in from a tty, not through a GUI.
            -- they logged in remotely, such as through ssh.
        - Non-login shell:          If the shell was started any other way, such as through GNOME’s gnome-terminal or KDE’s konsole, then it is typically not a login shell.

    Bash: >
        +----------------+-----------+-----------+---------------+
        |                |Interactive|Interactive|Non-interactive|
        |                |login      |non-login  |Script         |
        +----------------+-----------+-----------+---------------+
        |/etc/profile    |   A       |           |               | --noprofile
        +----------------+-----------+-----------+---------------+
        |/etc/bash.bashrc|           |    A      |               | --norc (--rcfile <file>)
        +----------------+-----------+-----------+---------------+
        |~/.bashrc       |           |    B      |               |
        +----------------+-----------+-----------+---------------+
        |~/.bash_profile |   B1      |           |               |
        +----------------+-----------+-----------+---------------+
        |~/.bash_login   |   B2      |           |               |
        +----------------+-----------+-----------+---------------+
        |~/.profile      |   B3      |           |               |
        +----------------+-----------+-----------+---------------+
        |BASH_ENV        |           |           |  A            |
        +----------------+-----------+-----------+---------------+
        |...........     |           |           |               |
        +----------------+-----------+-----------+---------------+
        |~/.bash_logout  |    C      |           |               | shell exit
        +----------------+-----------+-----------+---------------+
                          --login
<
    Zsh: >
        +----------------+-----------+-----------+------+
        |                |Interactive|Interactive|Script|
        |                |login      |non-login  |      |
        +----------------+-----------+-----------+------+
        |/etc/zshenv     |    A      |    A      |  A   |
        +----------------+-----------+-----------+------+
        |~/.zshenv       |    B      |    B      |  B   |
        +----------------+-----------+-----------+------+
        |/etc/zprofile   |    C      |           |      |
        +----------------+-----------+-----------+------+
        |~/.zprofile     |    D      |           |      |
        +----------------+-----------+-----------+------+
        |/etc/zshrc      |    E      |    C      |      |
        +----------------+-----------+-----------+------+
        |~/.zshrc        |    F      |    D      |      |
        +----------------+-----------+-----------+------+
        |/etc/zlogin     |    G      |           |      |
        +----------------+-----------+-----------+------+
        |~/.zlogin       |    H      |           |      |
        +----------------+-----------+-----------+------+
        |.............   |           |           |      |
        +----------------+-----------+-----------+------+
        |~/.zlogout      |    I      |           |      | shell exit
        +----------------+-----------+-----------+------+
        |/etc/zlogout    |    J      |           |      |
        +----------------+-----------+-----------+------+
<
    Note:
        For bash, put stuff in ~/.bashrc, and make ~/.bash_profile source it.
        For zsh, put stuff in ~/.zshrc, which is always executed.

    Bash check: >
        if [[ -n $PS1 ]]; then
            echo "interactive"
        else
            echo "non-interactive"  # bash script
        fi
        if shopt -q login_shell ; then  # --login option
            echo "login"
        else
            echo "nonlogin"
        fi

46. 使用binfmt_misc设定不同二进制的打开程序
    在Windows平台上，可以绑定拥有特定扩展名的文件，使用特定的程序打开。比如，PDF文件就使用Acrobat Reader打开。这样做确实极大的方便了用户的使用体验。

    其实，在Linux平台上，也提供了类似的功能，甚至从某种意义上来说更加的强大。Linux的内核从很早开始就引入了一个叫做
    Miscellaneous Binary Format（binfmt_misc）的机制，可以通过要打开文件的特性来选择到底使用哪个程序来打开。
    比Windows更加强大的地方是，它不光光可以通过文件的扩展名来判断的，还可以通过文件开始位置的特殊的字节（Magic Byte）来判断。

    如果要使用这个功能的话，首先要绑定binfmt_misc，可以通过以下命令来绑定：
    $ mount binfmt_misc -t binfmt_misc /proc/sys/fs/binfmt_misc
    这样绑定的话，系统重新启动之后就失效了。如果想让系统每次启动的时候都自动绑定的话，可以往/etc/fstab文件中加入下面这行：
    none  /proc/sys/fs/binfmt_misc binfmt_misc defaults 0 0

    绑定完之后，就可以通过向/proc/sys/fs/binfmt_misc/register（这个文件只能写不能读）文件中写入一行匹配规则字符
    串来告诉内核什么样的程序要用什么样的程序打开（一般使用echo命令）。这行字符串的格式如下：
    :name:type:offset:magic:mask:interpreter:flags ~
    每个字段都用冒号“:”分割。某些字段拥有默认值，或者只在前面字段被设置成了某个特定值后才有效，因此可以跳过某些字段的设置，但是必须保留相应的冒号分割符。各个字段的意义如下：

    1）name：
        这个规则的名字，理论上可以取任何名字，只要不重名就可以了。但是为了方便以后维护一般都取一个有意义的名字，
        比如表示被打开文件特性的名字，或者要打开这个文件的程序的名字等；
    2）type：
        表示如何匹配被打开的文件，只可以使用“E”或者“M”，只能选其一，两者不可共用。
        “E”代表只根据待打开文件的扩展名来识别，而“M”表示只根据待打开文件特定位置的几位魔数（Magic Byte）来识别；
    3）offset：
        这个字段只对前面type字段设置成“M”之后才有效，它表示从文件的多少偏移开始查找要匹配的魔数。
        如果跳过这个字断不设置的话，默认就是0；
    4）magic：
        它表示真正要匹配的魔数，如果type字段设置成“M”的话；或者表示文件的扩展名，如果type字段设置成“E”的话。
        对于匹配魔数来说，如果要匹配的魔数是ASCII码可见字符，可以直接输入，而如果是不可见的话，可以输入其16进制数值，
        前面加上“\x”或者“\\x”（如果在Shell环境中的话。对于匹配文件扩展名来说，就在这里写上文件的扩展名，
        但不要包括扩展名前面的点号（“.”），且这个扩展名是大小写敏感的，有些特殊的字符，例如目录分隔符正斜杠（“/”）是不允许输入的；
    5）mask：
        同样，这个字段只对前面type字段设置成“M”之后才有效。它表示要匹配哪些位，它的长度要和magic字段魔数的长度一致。
        如果某一位为1，表示这一位必须要与magic对应的位匹配；如果对应的位为0，表示忽略对这一位的匹配，取什么值都可以。
        如果是0xff的话，即表示全部位都要匹配，默认情况下，如果不设置这个字段的话，表示要与magic全部匹配（即等效于所有都设置成0xff）。
        还有同样对于NUL来说，要使用转义（\x00），否则对这行字符串的解释将到NUL停止，后面的不再起作用；
    6）interpreter：
        表示要用哪个程序来启动这个类型的文件，一定要使用全路径名，不要使用相对路径名；
    7）flags：
        这个字段可选，主要用来控制interpreter打开文件的行为。比较常用的是‘P’（请注意，一定要大写），
        表示保留原始的argv[0]参数。这是什么意思呢？默认情况下，如果不设置这个标志的话，binfmt_misc会将传给
        interpreter的第一个参数，即argv[0]，修改成要被打开文件的全路径名。当设置了‘P’之后，binfmt_misc会保留原来的argv[0]，
        在原来的argv[0]和argv[1]之间插入一个参数，用来存放要被打开文件的全路径名。比如，
        如果想用程序/bin/foo来打开/usr/local/bin/blah这个文件，如果不设置‘P’的话，
        传给程序/bin/foo的参数列表argv[]是["/usr/local/bin/blah", "blah"]，而如果设置了‘P’之后，
        程序/bin/foo得到的参数列表是["/bin/foo", "/usr/local/bin/blah", "blah"]。

    除了以上的规则之外，还有一些额外的限制条件：

    1）每一行匹配规则字符串的长度不能超过1920个字符；
    2）魔数（Magic Byte）必须在文件头128个字节内，也就是说offset+sizeof(magic)不能超过128；
    3）interpreter字段的长度不能超过127个字符。

    每次成功写入一行规则，都会在/proc/sys/fs/binfmt_misc/目录下，创建一个名字为输入的匹配规则字符串中"name"字段的文件。

    通过读取这个文件的内容，可以知道这条匹配规则当前的状态：
    $ cat /proc/sys/fs/binfmt_misc/<name>

    而通过向这个文件中写入0或1，可以关闭或打开这条匹配规则，而写入-1表示彻底删除这条规则：
    $ echo 0 > /proc/sys/fs/binfmt_misc/<name>    # Disable the match
    $ echo 1 > /proc/sys/fs/binfmt_misc/<name>    # Enable the match
    $ echo -1 > /proc/sys/fs/binfmt_misc/<name>   # Delete the match
    不过前提是必须要切换到root用户才能有权限写入。

    在/proc/sys/fs/binfmt_misc/目录下，还缺省存在一个叫做status的文件，通过它可以查看和控制整个binfmt_misc的状态，而不光是单个匹配规则。

    可以查看当前binfmt_misc是否处于打开状态：
    $ cat /proc/sys/fs/binfmt_misc/status

    也可以通过向它写入1或0来打开或关闭binfmt_misc：
    $ echo 0 > /proc/sys/fs/binfmt_misc/status    # Disable binfmt_misc
    $ echo 1 > /proc/sys/fs/binfmt_misc/status    # Enable binfmt_misc

    如果想删除当前binfmt_misc中的所有匹配规则，可以向其传入-1：
    $ echo -1 > /proc/sys/fs/binfmt_misc/status    # Disable all matches

    例子：
        启动对DOS应用程序的支持
        $ echo ':DEXE:M::\x0eDEX::/usr/bin/dosexec:' > /proc/sys/fs/binfmt_misc/register

        启动使用wine对windows可执行程序的支持
        $ echo ':DOSWin:M::MZ::/usr/local/bin/wine:' > /proc/sys/fs/binfmt_misc/register

47. apt-get update特别慢，更新文件特别大
    Probably, apt-file was installed at some point and its entry (or "trigger" if i can say) got set in /etc/apt/apt.conf.d/
    Solution:
        - You could keep apt-file and disable its config in apt, using this commend:
            $ sudo sh /usr/share/doc/apt-file/examples/apt-file-2-update.sh --install
          Then you can use follow command separately as needed (Separation of concerns):
            $ apt update & apt-file update
        - Also you may tweak /etc/apt/apt-file.conf to set only needed indexes to be downloaded.
        - Purge apt-file if not required any more.
            $ sudo apt-get purge

48. SVN 不能存储密码
    如果svn不能存储密码的话，手动修改文件
    ~/.subversion/auth/svn.simple/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx >
        K 8
        passtype
        V 6
        simple
        K 8
        password
        V 5
        lq123
        K 15
        svn:realmstring
        V 54
        <https://swserver:443> Huntersun Subversion Repository
        K 8
        username
        V 7
        liqiang
        END

49. 报错处理：
    a. Wrong __data_start/_end pair
    能是libgc.so的问题
    用老版本的库替换：sudo ln -sf /usr/lib/x86_64-linux-gnu/libgc.so.1.0.3 /usr/lib/x86_64-linux-gnu/libgc.so.1


vim:ft=help
